{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Deep Learning Example with Keras\n",
    "\n",
    "This Deep Learning Example uses Keras to import MNIST data and create a two layer network to recognize handwritten digits  -JPR October 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick version check of Tensorflow can verify that it was properly loaded into the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import matplotlib.pyplot for data plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the MNIST data set from the Keras catalog.  This is a set of 60,000 28 x 28 images of handwritten digits used for deep learning training.  This code also imports the 10,000 28 x 28 validation images.  The size of the train_images data is shown with the shape method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display a single diigit from the Training Set using hte pyplot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = train_images[1005]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the models and layers function from Keras.  Thi is used to create the two layer neural network with a 'dense' fully connected architecture.  THe first layer connect from the input has 512 fully connected nodes and the next layer has 110 fully connected loads that serve as the output identification of each digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the 'engine' of the neural network including the optimizer that impliments the gradient decent methods and the loss function that captures the error from the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the Image Data by reshaping from a 3D data structure to a 2D one with each image stacked into a single vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32')/255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the 'fit' method to actually train the network.  The number of epochs or times the algorithm will run through the entire data is set, along with the individual batch size.  The batch size is the number of inputs the algorithm can process in one step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 14s 230us/step - loss: 0.2574 - acc: 0.9243\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.1054 - acc: 0.9686\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0696 - acc: 0.9798\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0500 - acc: 0.9846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f34df3c2e10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=4, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the evaluate method to test the newly trained network on the validation or 'test images'.  This is the set of 10,000 images with handwritten digits the training algorithm has not yet encountered.  The performace of the trained neural network is documented in the test loss and test accuracy measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 153us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test_acc:', 0.9785)\n"
     ]
    }
   ],
   "source": [
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My Linux Laptob ran this case and had an accuracy of 97.85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
